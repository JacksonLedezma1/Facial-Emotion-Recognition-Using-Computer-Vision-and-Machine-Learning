# Proyecto de DetecciÃ³n de Emociones Faciales

Este proyecto permite detectar la **emociÃ³n principal** en imÃ¡genes utilizando la biblioteca [`fer`](https://github.com/justinshenk/fer), combinada con OpenCV y Matplotlib para el procesamiento y visualizaciÃ³n de imÃ¡genes.

## ğŸ“¦ Requisitos

Instala las dependencias necesarias con:
```bash
pip install fer opencv-python matplotlib
```
## ğŸ—‚ï¸ Dataset de ImÃ¡genes

Para que el modelo pueda detectar emociones, es necesario contar con un conjunto de imÃ¡genes faciales.

### ğŸ”¹ OpciÃ³n 1: Subir tus propias imÃ¡genes

1. Coloca tus imÃ¡genes en una carpeta local o en tu Google Drive (si usas Google Colab).
2. AsegÃºrate de que las imÃ¡genes estÃ©n en formato compatible como `.jpg`, `.png`, etc.
3. Ejemplo de estructura:


### ğŸ”¹ OpciÃ³n 2: Usar un dataset pÃºblico

Puedes descargar un dataset de emociones faciales como:

- [FER-2013 (Facial Expression Recognition)](https://www.kaggle.com/datasets/msambare/fer2013)
- [Facial Emotion Recognition Dataset (Extended KUCEV ROMAN)](https://www.kaggle.com/datasets/tapakah68/facial-emotion-recognition?select=images)

DespuÃ©s de descargarlo:

1. Extrae las imÃ¡genes.
2. Organiza las carpetas (pueden estar clasificadas por emociÃ³n o en una sola carpeta, segÃºn tu cÃ³digo).
3. Cambia la ruta en el script Python para apuntar al directorio correcto.

```python
img_dir = "/ruta/a/tu/dataset"
```

##ğŸ“ Estructura de Carpetas

Coloca tus imÃ¡genes en un directorio. Por ejemplo:
```bash
Proyecto_Final/
â””â”€â”€ Quick/
    â”œâ”€â”€ imagen1.jpg
    â”œâ”€â”€ imagen2.jpg
    â””â”€â”€ ...
```
## ğŸ§  CÃ³digo Explicado
```bash
# Importar bibliotecas necesarias
from IPython import get_ipython             # Para trabajar con entornos IPython (como Colab)
from IPython.display import display         # Para mostrar elementos multimedia
from fer import FER                         # Detector de emociones
import cv2                                  # Procesamiento de imÃ¡genes
import matplotlib.pyplot as plt             # VisualizaciÃ³n
import os                                   # Manejo del sistema de archivos

# Configurar la ruta de las imÃ¡genes
img_dir = "/content/drive/MyDrive/Vision_Artificial/Proyecto_Final/Quick"  # Reemplaza con tu ruta

# Obtener la lista de imÃ¡genes del directorio
img_files = [f for f in os.listdir(img_dir) if os.path.isfile(os.path.join(img_dir, f))]

# Inicializar el detector de emociones
detector = FER()

# Iterar sobre cada imagen
for img_file in img_files:
    # Cargar imagen
    img_path = os.path.join(img_dir, img_file)
    img = cv2.imread(img_path)

    # Mostrar imagen
    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))  # Convertir de BGR a RGB
    plt.axis('off')
    plt.title(img_file)
    plt.show()

    # Detectar emociÃ³n principal
    result = detector.top_emotion(img)
    print(f"{img_file}: {result}")
```
## ğŸ“ Notas

-Este cÃ³digo estÃ¡ pensado para usarse en Google Colab o Jupyter Notebook.

-AsegÃºrate de montar tu Google Drive si trabajas en Colab.

-La funciÃ³n top_emotion() devuelve una tupla como ('happy', 0.98) representando la emociÃ³n detectada y su probabilidad.
